{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This is the code to create the dataset for training/validation","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-01T06:42:19.91326Z","iopub.execute_input":"2023-06-01T06:42:19.913685Z","iopub.status.idle":"2023-06-01T06:42:26.089112Z","shell.execute_reply.started":"2023-06-01T06:42:19.913653Z","shell.execute_reply":"2023-06-01T06:42:26.088022Z"}}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\nimport pickle\nfrom torch.utils.data import DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nimport warnings\nimport sys\nimport pandas as pd\nimport os\nimport gc\nimport sys\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nimport cv2\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport argparse\nimport importlib\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD, AdamW\n\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:06.091710Z","iopub.execute_input":"2023-06-01T10:27:06.092025Z","iopub.status.idle":"2023-06-01T10:27:11.382247Z","shell.execute_reply.started":"2023-06-01T10:27:06.091996Z","shell.execute_reply":"2023-06-01T10:27:11.381243Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:11.384421Z","iopub.execute_input":"2023-06-01T10:27:11.385294Z","iopub.status.idle":"2023-06-01T10:27:28.551123Z","shell.execute_reply.started":"2023-06-01T10:27:11.385259Z","shell.execute_reply":"2023-06-01T10:27:28.549910Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting segmentation_models_pytorch\n  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.15.1)\nCollecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: timm==0.9.2 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.9.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (4.64.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (9.5.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (3.0.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (5.4.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.14.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.28.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2023.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (21.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.5.7)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=05e17ef3b50edc82a1ed5d91ed74ed6143c207b0464edb092c9fcfaa1fc4132f\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60966 sha256=63f9452f5e2fcc823e818d2618759174e37368924c5e407f7a0918da8308e377\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: efficientnet-pytorch, pretrainedmodels, segmentation_models_pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:28.557488Z","iopub.execute_input":"2023-06-01T10:27:28.558764Z","iopub.status.idle":"2023-06-01T10:27:31.125462Z","shell.execute_reply.started":"2023-06-01T10:27:28.558726Z","shell.execute_reply":"2023-06-01T10:27:31.124521Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install warmup_scheduler","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:31.128068Z","iopub.execute_input":"2023-06-01T10:27:31.128809Z","iopub.status.idle":"2023-06-01T10:27:44.030875Z","shell.execute_reply.started":"2023-06-01T10:27:31.128772Z","shell.execute_reply":"2023-06-01T10:27:44.029742Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting warmup_scheduler\n  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: warmup_scheduler\n  Building wheel for warmup_scheduler (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for warmup_scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2982 sha256=87afab1ba4e4c195de3d35cbeb689fddc88ad2c4641de3eb6eace3ea362e2bbf\n  Stored in directory: /root/.cache/pip/wheels/59/01/9e/d1820991c32916e9808c940f572b462f3e46427f3e76c4d852\nSuccessfully built warmup_scheduler\nInstalling collected packages: warmup_scheduler\nSuccessfully installed warmup_scheduler-0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nimport cv2\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:44.032642Z","iopub.execute_input":"2023-06-01T10:27:44.033339Z","iopub.status.idle":"2023-06-01T10:27:45.191954Z","shell.execute_reply.started":"2023-06-01T10:27:44.033298Z","shell.execute_reply":"2023-06-01T10:27:45.191015Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"markdown","source":"**We can change the stride, tile size, number of channels etc here**","metadata":{}},{"cell_type":"code","source":"import os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass CFG:\n    # ============== comp exp name =============\n    comp_name = 'vesuvius'\n\n    # comp_dir_path = './'\n    comp_dir_path = '/kaggle/input/'\n    comp_folder_name = 'vesuvius-challenge-ink-detection'\n    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n    \n    exp_name = 'vesuvius_2d_slide_exp021'\n\n    # ============== pred target =============\n    target_size = 1\n\n    # ============== model cfg =============\n    model_name = 'Unet'\n#     backbone = 'efficientnet-b0'\n    backbone = 'mit_b2'\n\n    in_chans = 3 # 65\n    # ============== training cfg =============\n    size = 224\n    tile_size = 224\n    stride = tile_size \n\n    train_batch_size = 16 # 32\n    valid_batch_size = train_batch_size * 2\n    use_amp = True    #automatic mixed precission\n\n    scheduler = 'GradualWarmupSchedulerV2'     #study about the schedulers...\n    # scheduler = 'CosineAnnealingLR'\n    epochs = 15 # 30\n\n    # adamW warmupあり\n    warmup_factor = 10\n    # lr = 1e-4 / warmup_factor\n    lr = 1e-4 / warmup_factor\n\n    # ============== fold =============\n    \n\n    # objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n    metric_direction = 'maximize'  # maximize, 'minimize'\n    # metrics = 'dice_coef'\n\n    # ============== fixed =============\n    pretrained = True\n    inf_weight = 'best'  # 'best'\n\n    min_lr = 1e-6\n    weight_decay = 1e-6\n    max_grad_norm = 1000\n\n    print_freq = 50\n    num_workers = 4\n\n    seed = 42\n\n    # ============== set dataset path =============\n    print('set dataset path')\n\n    outputs_path = f'/kaggle/working/outputs/{comp_name}/{exp_name}/'\n\n    submission_dir = outputs_path + 'submissions/'\n    submission_path = submission_dir + f'submission_{exp_name}.csv'\n\n    model_dir = outputs_path + \\\n        f'{comp_name}-models/'\n    \n    data_dir = outputs_path + \\\n        f'{comp_name}-data/'\n\n    figures_dir = outputs_path + 'figures/'\n\n    log_dir = outputs_path + 'logs/'\n    log_path = log_dir + f'{exp_name}.txt'\n\n    # ============== augmentation =============\n    train_aug_list = [\n        # A.RandomResizedCrop(\n        #     size, size, scale=(0.85, 1.0)),\n        A.Resize(size, size),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.RandomBrightnessContrast(p=0.75),\n        A.ShiftScaleRotate(p=0.75),\n        A.OneOf([\n                A.GaussNoise(var_limit=[10, 50]),\n                A.GaussianBlur(),\n                A.MotionBlur(),\n                ], p=0.4),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n                        mask_fill_value=0, p=0.5),\n        # A.Cutout(max_h_size=int(size * 0.6),\n        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n\n    valid_aug_list = [\n        A.Resize(size, size),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:45.193568Z","iopub.execute_input":"2023-06-01T10:27:45.193938Z","iopub.status.idle":"2023-06-01T10:27:45.210781Z","shell.execute_reply.started":"2023-06-01T10:27:45.193904Z","shell.execute_reply":"2023-06-01T10:27:45.209719Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"set dataset path\n","output_type":"stream"}]},{"cell_type":"code","source":"def init_logger(log_file):\n    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\ndef set_seed(seed=None, cudnn_deterministic=True):\n    if seed is None:\n        seed = 42\n\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = cudnn_deterministic\n    torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:45.212253Z","iopub.execute_input":"2023-06-01T10:27:45.212863Z","iopub.status.idle":"2023-06-01T10:27:45.250111Z","shell.execute_reply.started":"2023-06-01T10:27:45.212830Z","shell.execute_reply":"2023-06-01T10:27:45.249142Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:45.251753Z","iopub.execute_input":"2023-06-01T10:27:45.252517Z","iopub.status.idle":"2023-06-01T10:27:45.260705Z","shell.execute_reply.started":"2023-06-01T10:27:45.252484Z","shell.execute_reply":"2023-06-01T10:27:45.259782Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def make_dirs(cfg):\n    for dir in [cfg.model_dir, cfg.figures_dir, cfg.submission_dir, cfg.log_dir, CFG.data_dir]:\n        os.makedirs(dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:45.262085Z","iopub.execute_input":"2023-06-01T10:27:45.262580Z","iopub.status.idle":"2023-06-01T10:27:45.273476Z","shell.execute_reply.started":"2023-06-01T10:27:45.262550Z","shell.execute_reply":"2023-06-01T10:27:45.272578Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def cfg_init(cfg, mode='train'):\n    set_seed(cfg.seed)\n    # set_env_name()\n    # set_dataset_path(cfg)\n\n    if mode == 'train':\n        make_dirs(cfg)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:45.278307Z","iopub.execute_input":"2023-06-01T10:27:45.278599Z","iopub.status.idle":"2023-06-01T10:27:45.284893Z","shell.execute_reply.started":"2023-06-01T10:27:45.278576Z","shell.execute_reply":"2023-06-01T10:27:45.283453Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"cfg_init(CFG)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nLogger = init_logger(log_file=CFG.log_path)\n\nLogger.info('\\n\\n-------- exp_info -----------------')\n# Logger.info(datetime.datetime.now().strftime('%Y年%m月%d日 %H:%M:%S'))","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:45.287166Z","iopub.execute_input":"2023-06-01T10:27:45.287963Z","iopub.status.idle":"2023-06-01T10:27:45.324239Z","shell.execute_reply.started":"2023-06-01T10:27:45.287931Z","shell.execute_reply":"2023-06-01T10:27:45.323445Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\n\n-------- exp_info -----------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Change the input channels according to trainig config","metadata":{}},{"cell_type":"code","source":"def read_image_mask(fragment_id):\n\n    images = []\n\n    # idxs = range(65)\n    mid = 65 // 2\n    start = 29\n    end = 32\n#     start = mid - CFG.in_chans // 2\n#     end = mid + CFG.in_chans // 2\n    idxs = range(start, end)\n\n    for i in tqdm(idxs):\n        \n        image = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n\n        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n\n        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n\n        images.append(image)\n    images = np.stack(images, axis=2)\n\n    mask = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n\n    mask = mask.astype('float32')\n    mask /= 255.0\n    \n    return images, mask","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:45.326285Z","iopub.execute_input":"2023-06-01T10:27:45.327320Z","iopub.status.idle":"2023-06-01T10:27:45.335848Z","shell.execute_reply.started":"2023-06-01T10:27:45.327288Z","shell.execute_reply":"2023-06-01T10:27:45.334811Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_train_valid_dataset():\n    images = []\n    masks = []\n    xyxys = []\n    fragment_no = []\n\n    for fragment_id in range(1, 4):\n\n        image, mask = read_image_mask(fragment_id)\n        print(image.shape)\n\n        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n\n        for y1 in y1_list:\n            for x1 in x1_list:\n                y2 = y1 + CFG.tile_size\n                x2 = x1 + CFG.tile_size\n                # xyxys.append((x1, y1, x2, y2))\n        \n                \n                images.append(image[y1:y2, x1:x2])\n                masks.append(mask[y1:y2, x1:x2, None])\n                fragment_no.append(fragment_id)\n                xyxys.append([x1, y1, x2, y2])\n               \n\n    return images, masks, xyxys, fragment_no","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:45.337406Z","iopub.execute_input":"2023-06-01T10:27:45.337815Z","iopub.status.idle":"2023-06-01T10:27:45.347331Z","shell.execute_reply.started":"2023-06-01T10:27:45.337784Z","shell.execute_reply":"2023-06-01T10:27:45.346362Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"images, masks, xyxys, frag_no = get_train_valid_dataset()","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:27:45.348699Z","iopub.execute_input":"2023-06-01T10:27:45.349140Z","iopub.status.idle":"2023-06-01T10:28:07.743367Z","shell.execute_reply.started":"2023-06-01T10:27:45.349108Z","shell.execute_reply":"2023-06-01T10:28:07.741469Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c05248849e18487789447d6aa20b679e"}},"metadata":{}},{"name":"stdout","text":"(8288, 6496, 3)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f59d2b79c5f4953b5a8ef1863098e17"}},"metadata":{}},{"name":"stdout","text":"(15008, 9632, 3)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da736caae1a14d39a7d68875da6d53d5"}},"metadata":{}},{"name":"stdout","text":"(7616, 5376, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# xyxys = np.stack(xyxys)   USE THIS CODE FOR TRAINING LATER ON ","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:07.744870Z","iopub.execute_input":"2023-06-01T10:28:07.745233Z","iopub.status.idle":"2023-06-01T10:28:07.749560Z","shell.execute_reply.started":"2023-06-01T10:28:07.745198Z","shell.execute_reply":"2023-06-01T10:28:07.748572Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"len(images),len(masks),len(xyxys),len(frag_no)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:07.751125Z","iopub.execute_input":"2023-06-01T10:28:07.751838Z","iopub.status.idle":"2023-06-01T10:28:07.763634Z","shell.execute_reply.started":"2023-06-01T10:28:07.751805Z","shell.execute_reply":"2023-06-01T10:28:07.762361Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(4770, 4770, 4770, 4770)"},"metadata":{}}]},{"cell_type":"code","source":"type(images),type(masks)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:07.765080Z","iopub.execute_input":"2023-06-01T10:28:07.765490Z","iopub.status.idle":"2023-06-01T10:28:07.774426Z","shell.execute_reply.started":"2023-06-01T10:28:07.765461Z","shell.execute_reply":"2023-06-01T10:28:07.773589Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(list, list)"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.DataFrame({'Frag_no': pd.Series(frag_no),\n                   'Images': pd.Series(images),\n                   'Masks': pd.Series(masks),\n                   'XYXYS': pd.Series(xyxys)})","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:07.775881Z","iopub.execute_input":"2023-06-01T10:28:07.776358Z","iopub.status.idle":"2023-06-01T10:28:07.791821Z","shell.execute_reply.started":"2023-06-01T10:28:07.776328Z","shell.execute_reply":"2023-06-01T10:28:07.790975Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:07.794908Z","iopub.execute_input":"2023-06-01T10:28:07.795209Z","iopub.status.idle":"2023-06-01T10:28:41.091172Z","shell.execute_reply.started":"2023-06-01T10:28:07.795185Z","shell.execute_reply":"2023-06-01T10:28:41.089996Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"   Frag_no                                             Images  \\\n0        1  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...   \n1        1  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...   \n2        1  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...   \n3        1  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...   \n4        1  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...   \n\n                                               Masks                XYXYS  \n0  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...     [0, 0, 224, 224]  \n1  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...   [224, 0, 448, 224]  \n2  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...   [448, 0, 672, 224]  \n3  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...   [672, 0, 896, 224]  \n4  [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  [896, 0, 1120, 224]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frag_no</th>\n      <th>Images</th>\n      <th>Masks</th>\n      <th>XYXYS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n      <td>[0, 0, 224, 224]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n      <td>[224, 0, 448, 224]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n      <td>[448, 0, 672, 224]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n      <td>[672, 0, 896, 224]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n      <td>[896, 0, 1120, 224]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:41.092803Z","iopub.execute_input":"2023-06-01T10:28:41.093197Z","iopub.status.idle":"2023-06-01T10:28:41.108572Z","shell.execute_reply.started":"2023-06-01T10:28:41.093164Z","shell.execute_reply":"2023-06-01T10:28:41.107449Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(4770, 4)"},"metadata":{}}]},{"cell_type":"code","source":"data_csv = CFG.data_dir+'data.csv'\ndf.to_csv(data_csv, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:41.109885Z","iopub.execute_input":"2023-06-01T10:28:41.110309Z","iopub.status.idle":"2023-06-01T10:28:46.288588Z","shell.execute_reply.started":"2023-06-01T10:28:41.110275Z","shell.execute_reply":"2023-06-01T10:28:46.287639Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Stratified K Fold","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:46.289873Z","iopub.execute_input":"2023-06-01T10:28:46.290837Z","iopub.status.idle":"2023-06-01T10:28:46.295631Z","shell.execute_reply.started":"2023-06-01T10:28:46.290797Z","shell.execute_reply":"2023-06-01T10:28:46.294521Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"num_folds = 5  # Number of folds for cross-validation\nskf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:46.296997Z","iopub.execute_input":"2023-06-01T10:28:46.297886Z","iopub.status.idle":"2023-06-01T10:28:46.310418Z","shell.execute_reply.started":"2023-06-01T10:28:46.297844Z","shell.execute_reply":"2023-06-01T10:28:46.309497Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nimport cv2\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:46.311991Z","iopub.execute_input":"2023-06-01T10:28:46.312506Z","iopub.status.idle":"2023-06-01T10:28:46.320316Z","shell.execute_reply.started":"2023-06-01T10:28:46.312472Z","shell.execute_reply":"2023-06-01T10:28:46.319126Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def get_transforms(data, cfg):\n    if data == 'train':\n        aug = A.Compose(cfg.train_aug_list)\n    elif data == 'valid':\n        aug = A.Compose(cfg.valid_aug_list)\n\n    # print(aug)\n    return aug\n\nclass CustomDataset(Dataset):\n    def __init__(self, images, cfg, labels=None, transform=None):\n        self.images = images\n        self.cfg = cfg\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        # return len(self.df)\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            data = self.transform(image=image, mask=label)\n            image = data['image']\n            label = data['mask']\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:28:46.322431Z","iopub.execute_input":"2023-06-01T10:28:46.322853Z","iopub.status.idle":"2023-06-01T10:28:46.332464Z","shell.execute_reply.started":"2023-06-01T10:28:46.322819Z","shell.execute_reply":"2023-06-01T10:28:46.331456Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, weight=None):\n        super().__init__()\n        self.cfg = cfg\n\n        self.encoder = smp.Unet(\n            encoder_name=cfg.backbone, \n            encoder_weights=weight,\n            in_channels=cfg.in_chans,\n            classes=cfg.target_size,\n            activation=None,\n        )\n\n    def forward(self, image):\n        output = self.encoder(image)\n        # output = output.squeeze(-1)\n        return output\n\n\ndef build_model(cfg, weight=\"imagenet\"):\n    print('model_name', cfg.model_name)\n    print('backbone', cfg.backbone)\n\n    model = CustomModel(cfg, weight)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:29:47.531961Z","iopub.execute_input":"2023-06-01T10:29:47.532320Z","iopub.status.idle":"2023-06-01T10:29:47.539437Z","shell.execute_reply.started":"2023-06-01T10:29:47.532291Z","shell.execute_reply":"2023-06-01T10:29:47.538566Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\nimport torch.nn as nn\nimport torch\nimport math\nimport time\nimport numpy as np\nimport torch\n\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nfrom warmup_scheduler import GradualWarmupScheduler\n\n\nclass GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    \"\"\"\n    https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n    \"\"\"\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(\n            optimizer, multiplier, total_epoch, after_scheduler)\n\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [\n                        base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\ndef get_scheduler(cfg, optimizer):\n    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, cfg.epochs, eta_min=1e-7)\n    scheduler = GradualWarmupSchedulerV2(\n        optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n\n    return scheduler\n\ndef scheduler_step(scheduler, avg_val_loss, epoch):\n    scheduler.step(epoch)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:29:48.310687Z","iopub.execute_input":"2023-06-01T10:29:48.311050Z","iopub.status.idle":"2023-06-01T10:29:48.323756Z","shell.execute_reply.started":"2023-06-01T10:29:48.311020Z","shell.execute_reply":"2023-06-01T10:29:48.322678Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = build_model(CFG)\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr=CFG.lr)\nscheduler = get_scheduler(CFG, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:29:48.926923Z","iopub.execute_input":"2023-06-01T10:29:48.927274Z","iopub.status.idle":"2023-06-01T10:29:57.459353Z","shell.execute_reply.started":"2023-06-01T10:29:48.927245Z","shell.execute_reply":"2023-06-01T10:29:57.458316Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"model_name Unet\nbackbone mit_b2\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://github.com/qubvel/segmentation_models.pytorch/releases/download/v0.0.2/mit_b2.pth\" to /root/.cache/torch/hub/checkpoints/mit_b2.pth\n100%|██████████| 94.3M/94.3M [00:02<00:00, 33.6MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"\nDiceLoss = smp.losses.DiceLoss(mode='binary')\nBCELoss = smp.losses.SoftBCEWithLogitsLoss()\n\nalpha = 0.5\nbeta = 1 - alpha\nTverskyLoss = smp.losses.TverskyLoss(\n    mode='binary', log_loss=False, alpha=alpha, beta=beta)    #Tversky coefficient = (true positives) / ((true positives) + alpha * (false negatives) + beta * (false positives))\n\ndef criterion(y_pred, y_true):\n    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n    return BCELoss(y_pred, y_true)\n    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * TverskyLoss(y_pred, y_true)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:29:57.465560Z","iopub.execute_input":"2023-06-01T10:29:57.468673Z","iopub.status.idle":"2023-06-01T10:29:57.477364Z","shell.execute_reply.started":"2023-06-01T10:29:57.468634Z","shell.execute_reply":"2023-06-01T10:29:57.476133Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, device):\n    model.train()\n\n    scaler = GradScaler(enabled=CFG.use_amp)\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with autocast(CFG.use_amp):\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n\n        losses.update(loss.item(), batch_size)\n        scaler.scale(loss).backward()\n\n        grad_norm = torch.nn.utils.clip_grad_norm_(\n            model.parameters(), CFG.max_grad_norm)\n\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n    return losses.avg\n\ndef valid_fn(valid_loader, model, criterion, device):\n\n    model.eval()\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with torch.no_grad():\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        \n        y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n\n\n\n    return losses.avg, y_preds, labels.to('cpu').numpy()","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:43:57.045055Z","iopub.execute_input":"2023-06-01T10:43:57.045448Z","iopub.status.idle":"2023-06-01T10:43:57.056503Z","shell.execute_reply.started":"2023-06-01T10:43:57.045410Z","shell.execute_reply":"2023-06-01T10:43:57.055443Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\n\ndef fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n    \"\"\"\n    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n    \"\"\"\n    y_true_count = targets.sum()\n    ctp = preds[targets==1].sum()\n    cfp = preds[targets==0].sum()\n    beta_squared = beta * beta\n\n    c_precision = ctp / (ctp + cfp + smooth)\n    \n    c_recall = ctp / (y_true_count + smooth)\n    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n\n    return dice\n\ndef calc_fbeta(mask, mask_pred):\n    mask = mask.flatten()\n    mask_pred = mask_pred.flatten()\n\n    best_th = 0\n    best_dice = 0\n    for th in np.array(range(10, 50+1, 5)) / 100:\n        \n        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n        dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n        print(f'th: {th}, fbeta: {dice}')\n\n        if dice > best_dice:\n            best_dice = dice\n            best_th = th\n    \n    Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n    return best_dice, best_th\n\n\ndef calc_cv(mask_gt, mask_pred):\n    best_dice, best_th = calc_fbeta(mask_gt, mask_pred)\n\n    return best_dice, best_th","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:43:58.567680Z","iopub.execute_input":"2023-06-01T10:43:58.568414Z","iopub.status.idle":"2023-06-01T10:43:58.580336Z","shell.execute_reply.started":"2023-06-01T10:43:58.568362Z","shell.execute_reply":"2023-06-01T10:43:58.579426Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"X = df[['Images', 'Masks', 'XYXYS']]  # Features\ny = df['Frag_no']  # Stratification based on the \"Frag_no\" column\n\nfor train_index, val_index in skf.split(X, y):\n    fold=0\n    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n    train_images=X_train['Images'].tolist()\n    train_masks= X_train['Masks'].tolist()\n    valid_images= X_val['Images'].tolist()\n    valid_masks =X_val['Masks'].tolist()\n    valid_xyxys= X_val['XYXYS'].tolist()\n    \n    valid_xyxys = np.stack(valid_xyxys)  \n    \n    train_dataset = CustomDataset(\n    train_images, CFG, labels=train_masks, transform=get_transforms(data='train', cfg=CFG))\n    valid_dataset = CustomDataset(\n    valid_images, CFG, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n\n    train_loader = DataLoader(train_dataset,\n                          batch_size=CFG.train_batch_size,\n                          shuffle=True,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n                          )\n    valid_loader = DataLoader(valid_dataset,\n                          batch_size=CFG.valid_batch_size,\n                          shuffle=False,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    \n    \n    if CFG.metric_direction == 'minimize':\n        best_score = np.inf\n    elif CFG.metric_direction == 'maximize':\n        best_score = -1\n\n    best_loss = np.inf\n\n    for epoch in range(CFG.epochs):\n\n        start_time = time.time()\n\n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n\n        # eval\n        avg_val_loss, mask_pred, labels = valid_fn(\n            valid_loader, model, criterion, device)\n\n        scheduler_step(scheduler, avg_val_loss, epoch)\n\n        best_dice, best_th = calc_cv(labels, mask_pred)\n\n        # score = avg_val_loss\n        score = best_dice\n\n        elapsed = time.time() - start_time\n\n        Logger.info(\n            f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        # Logger.info(f'Epoch {epoch+1} - avgScore: {avg_score:.4f}')\n        Logger.info(\n            f'Epoch {epoch+1} - avgScore: {score:.4f}')\n    \n        if CFG.metric_direction == 'minimize':\n            update_best = score < best_score\n        elif CFG.metric_direction == 'maximize':\n            update_best = score > best_score\n    \n        if update_best:\n            best_loss = avg_val_loss\n            best_score = score\n    \n            Logger.info(\n                f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            Logger.info(\n                f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            \n            torch.save({'model': model.state_dict(),\n                        'preds': mask_pred},\n                        CFG.model_dir + f'{CFG.model_name}_fold{fold}_best.pth')\n    fold=fold+1\n            \n        \n            \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:47:10.124960Z","iopub.execute_input":"2023-06-01T10:47:10.125354Z","iopub.status.idle":"2023-06-01T10:48:58.489836Z","shell.execute_reply.started":"2023-06-01T10:47:10.125321Z","shell.execute_reply":"2023-06-01T10:48:58.488327Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/238 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e132017056784758b9b54397e04764f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da3084f7415e4258a823b66c43786cba"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\nbest_th: 0.2, fbeta: 0.08892129937524004\nEpoch 1 - avg_train_loss: 0.3223  avg_val_loss: 0.3280  time: 80s\nEpoch 1 - avgScore: 0.0889\nEpoch 1 - Save Best Score: 0.0889 Model\nEpoch 1 - Save Best Loss: 0.3280 Model\n","output_type":"stream"},{"name":"stdout","text":"th: 0.1, fbeta: 0.0597999735260184\nth: 0.15, fbeta: 0.08490064420910406\nth: 0.2, fbeta: 0.08892129937524004\nth: 0.25, fbeta: 0.0883442692478308\nth: 0.3, fbeta: 0.08244164420659959\nth: 0.35, fbeta: 0.034019814942039865\nth: 0.4, fbeta: 0.018852247823034237\nth: 0.45, fbeta: 0.0076929795400976315\nth: 0.5, fbeta: 0.0027462866382803176\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/238 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b305b3e0f0f548fe9d57780aebdeccd4"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[49], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# eval\u001b[39;00m\n\u001b[1;32m     48\u001b[0m avg_val_loss, mask_pred, labels \u001b[38;5;241m=\u001b[39m valid_fn(\n\u001b[1;32m     49\u001b[0m     valid_loader, model, criterion, device)\n","Cell \u001b[0;32mIn[46], line 17\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_preds, labels)\n\u001b[1;32m     16\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mitem(), batch_size)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39mparameters(), CFG\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n\u001b[1;32m     22\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"labels.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:37:43.089298Z","iopub.execute_input":"2023-06-01T10:37:43.089798Z","iopub.status.idle":"2023-06-01T10:37:43.097023Z","shell.execute_reply.started":"2023-06-01T10:37:43.089757Z","shell.execute_reply":"2023-06-01T10:37:43.095947Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"torch.Size([26, 1, 224, 224])"},"metadata":{}}]},{"cell_type":"code","source":"type(mask_pred)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:42:19.127196Z","iopub.execute_input":"2023-06-01T10:42:19.128152Z","iopub.status.idle":"2023-06-01T10:42:19.135123Z","shell.execute_reply.started":"2023-06-01T10:42:19.128115Z","shell.execute_reply":"2023-06-01T10:42:19.134168Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"dice = fbeta_numpy(labels, (mask_pred >= 0.4).astype(int), beta=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T10:41:00.661431Z","iopub.execute_input":"2023-06-01T10:41:00.661792Z","iopub.status.idle":"2023-06-01T10:41:00.731702Z","shell.execute_reply.started":"2023-06-01T10:41:00.661764Z","shell.execute_reply":"2023-06-01T10:41:00.730333Z"},"trusted":true},"execution_count":44,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dice \u001b[38;5;241m=\u001b[39m \u001b[43mfbeta_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[36], line 8\u001b[0m, in \u001b[0;36mfbeta_numpy\u001b[0;34m(targets, preds, beta, smooth)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mhttps://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m y_true_count \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m----> 8\u001b[0m ctp \u001b[38;5;241m=\u001b[39m \u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      9\u001b[0m cfp \u001b[38;5;241m=\u001b[39m preds[targets\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     10\u001b[0m beta_squared \u001b[38;5;241m=\u001b[39m beta \u001b[38;5;241m*\u001b[39m beta\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."],"ename":"TypeError","evalue":"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}